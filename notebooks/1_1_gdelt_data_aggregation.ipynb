{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "158d4c57-7769-4b95-a83a-5b1076de5125",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14285e38-514a-46f0-878d-006557d90162",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import requests\n",
    "import re\n",
    "import zipfile\n",
    "import pathlib\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from itertools import chain\n",
    "from psycopg2 import connect\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "302b60fd-e270-4f9f-a7dd-1f0fefb31ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_master_file_list(url):\n",
    "    r = requests.get(url)\n",
    "    if not r.ok:\n",
    "        raise BaseException(f\"Invalid HTML status {r.status_code}\")\n",
    "    raw_list = r.text.split(\"\\n\")\n",
    "    gkg_list = []\n",
    "    event_list = []\n",
    "    for raw in raw_list:\n",
    "        try:\n",
    "            file_location = re.search(r\"https?://[^\\s]+\", raw).group()\n",
    "        except AttributeError:\n",
    "            pass\n",
    "\n",
    "        if \".gkg\" in file_location:\n",
    "            gkg_list.append(file_location)\n",
    "\n",
    "        if \".export\" in file_location:\n",
    "            event_list.append(file_location)\n",
    "\n",
    "    return gkg_list, event_list\n",
    "\n",
    "\n",
    "def fetch_and_parse_zip(url):\n",
    "    r = requests.get(url)\n",
    "    if not r.ok:\n",
    "        csv = open(\"/tmp/gdelt_csv_empty_file.csv\", \"w+\")\n",
    "        return csv\n",
    "    file = r.content\n",
    "    zip_object = zipfile.ZipFile(io.BytesIO(file), \"r\")\n",
    "    csv = zip_object.open(zip_object.namelist()[0])\n",
    "\n",
    "    return csv\n",
    "\n",
    "\n",
    "def get_relevant_events_lines(content, words, aggregate_file):\n",
    "    for line in content.readlines():\n",
    "        try:\n",
    "            line = line.decode(\"utf-8\")\n",
    "            source_url = line.split(\"\\t\")[-1].strip(\"\\n\")\n",
    "            terms_in_url = re.split(r\"[-._/]+\", source_url)\n",
    "            if any([word in terms_in_url for word in words]):\n",
    "                aggregate_file.write(line)\n",
    "        except UnicodeDecodeError:\n",
    "            pass\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def get_gdelt_events_data(words, progress_file, file_list):\n",
    "    processed_files = [pf.strip() for pf in progress_file.readlines()]\n",
    "    N = len(file_list)\n",
    "    p = pathlib.Path(f\"../data\")\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "    q = p / \"gdelt_events.csv\"\n",
    "    with q.open(\"a+\") as agg:\n",
    "        start_time = time.time()\n",
    "        m = 0\n",
    "        for n, file_url in enumerate(file_list):\n",
    "            if file_url in processed_files:\n",
    "                m += 1\n",
    "                continue\n",
    "            csv = fetch_and_parse_zip(file_url)\n",
    "            get_relevant_events_lines(csv, words, agg)\n",
    "\n",
    "            clear_output(wait=True)\n",
    "\n",
    "            elapsed_time = time.time() - start_time\n",
    "\n",
    "            elapsed_time_tuple = str(datetime.timedelta(seconds=elapsed_time)).split(\n",
    "                \":\"\n",
    "            )\n",
    "\n",
    "            elapsed_time_string = f\"{elapsed_time_tuple[0]}:{elapsed_time_tuple[1]}:{round(float(elapsed_time_tuple[2])):02}\"\n",
    "\n",
    "            estimated_time_remaining = (\n",
    "                elapsed_time * (N - m) / (n - m + 1)\n",
    "            ) - elapsed_time\n",
    "\n",
    "            estimated_remaining_time_tuple = str(\n",
    "                datetime.timedelta(seconds=estimated_time_remaining)\n",
    "            ).split(\":\")\n",
    "\n",
    "            estimated_remaining_time_string = f\"{estimated_remaining_time_tuple[0]}:{estimated_remaining_time_tuple[1]}:{round(float(estimated_remaining_time_tuple[2])):02}\"\n",
    "\n",
    "            print(f\"{n + 1}/{N} files parsed\")\n",
    "            print(f\"Elapsed time: {elapsed_time_string}\")\n",
    "            print(f\"Estimated remaining time: {estimated_remaining_time_string}\")\n",
    "\n",
    "            progress_file.write(file_url + \"\\n\")\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8df6bb95-fb45-430d-8bd3-ebea5a8ce525",
   "metadata": {},
   "outputs": [],
   "source": [
    "gkg_list, events_list = get_master_file_list(\n",
    "    \"http://data.gdeltproject.org/gdeltv2/masterfilelist.txt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa4a407-11b9-4618-907e-9f858bde6ea5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeddedea-2d8a-4165-ade4-6c7f58cd4c2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1e3732e-b9b5-4947-9964-fd924b9277de",
   "metadata": {},
   "outputs": [],
   "source": [
    "OIL_WORDS = [\n",
    "    \"oil\",\n",
    "    \"gas\",\n",
    "    \"gasoline\",\n",
    "    \"petrol\",\n",
    "    \"fuel\",\n",
    "    \"petroleum\",\n",
    "    \"diesel\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ea4c5fa-1b2c-413b-9045-7dfdf83c9612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "272839/272839 files parsed\n",
      "Elapsed time: 0:10:20\n",
      "Estimated remaining time: 0:00:00\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open(\"../data/events_progress.txt\", \"r+\") as progress_file:\n",
    "        get_gdelt_events_data(OIL_WORDS, progress_file, events_list)\n",
    "except FileNotFoundError:\n",
    "    with open(\"../data/events_progress.txt\", \"w+\") as progress_file:\n",
    "        get_gdelt_events_data(OIL_WORDS, progress_file, events_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e15ff9f-a7ee-4b3a-8eae-0cc39a54e401",
   "metadata": {},
   "source": [
    "# SQL Hosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7137ec7-dcb5-49b6-a236-cb10244baa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "! sudo -S -i -u postgres dropdb -f gdelt < ../etc/user.password\n",
    "! sudo -S -i -u postgres createdb gdelt < ../etc/user.password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c3ed996-f72e-47ce-9f5a-397cffb0bb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_columns = \"\"\"id serial PRIMARY KEY,\n",
    "                   GlobalEventID integer, \n",
    "                   Day integer,\n",
    "                   MonthYear integer,\n",
    "                   Year integer,\n",
    "                   FractionDate numeric,\n",
    "                   Actor1Code text,\n",
    "                   Actor1Name text,\n",
    "                   Actor1CountryCode text,\n",
    "                   Actor1KnownGroupCode text,\n",
    "                   Actor1EthnicCode text,\n",
    "                   Actor1Religion1Code text,\n",
    "                   Actor1Religion2Code text,\n",
    "                   Actor1Type1Code text,\n",
    "                   Actor1Type2Code text,\n",
    "                   Actor1Type3Code text,\n",
    "                   Actor2Code text,\n",
    "                   Actor2Name text,\n",
    "                   Actor2CountryCode text,\n",
    "                   Actor2KnownGroupCode text,\n",
    "                   Actor2EthnicCode text,\n",
    "                   Actor2Religion1Code text,\n",
    "                   Actor2Religion2Code text,\n",
    "                   Actor2Type1Code text,\n",
    "                   Actor2Type2Code text,\n",
    "                   Actor2Type3Code text,\n",
    "                   IsRootEvent integer,\n",
    "                   EventCode text,\n",
    "                   EventBaseCode text,\n",
    "                   EventRootCode text,\n",
    "                   QuadClass integer,\n",
    "                   GoldsteinScale text,\n",
    "                   NumMentions integer,\n",
    "                   NumSources integer,\n",
    "                   NumArticles integer,\n",
    "                   AvgTone numeric,\n",
    "                   Actor1Geo_Type integer,\n",
    "                   Actor1Geo_Fullname text,\n",
    "                   Actor1Geo_CountryCode text,\n",
    "                   Actor1Geo_ADM1Code text,\n",
    "                   Actor1Geo_ADM2Code text,\n",
    "                   Actor1Geo_Lat text,\n",
    "                   Actor1Geo_Long text,\n",
    "                   Actor1Geo_FeatureID text,\n",
    "                   Actor2Geo_Type integer,\n",
    "                   Actor2Geo_Fullname text,\n",
    "                   Actor2Geo_CountryCode text,\n",
    "                   Actor2Geo_ADM1Code text,\n",
    "                   Actor2Geo_ADM2Code text,\n",
    "                   Actor2Geo_Lat text,\n",
    "                   Actor2Geo_Long text,\n",
    "                   Actor2Geo_FeatureID text,\n",
    "                   ActionGeo_Type integer,\n",
    "                   ActionGeo_Fullname text,\n",
    "                   ActionGeo_CountryCode text,\n",
    "                   ActionGeo_ADM1Code text,\n",
    "                   ActionGeo_ADM2Code text,\n",
    "                   ActionGeo_Lat text,\n",
    "                   ActionGeo_Long text,\n",
    "                   ActionGeo_FeatureID text,\n",
    "                   DATEADDED bigint,\n",
    "                   SOURCEURL text\"\"\"\n",
    "\n",
    "# NOTE: strictly speaking, many columns (such as GoldsteinScale)\n",
    "# should be of type numeric. However, these columns contain\n",
    "# empty strings in the .csv files. This will cause issues\n",
    "# in the COPY FROM postgreSQL command. Therefore, we treat\n",
    "# these columns as text initially. If reason is found to use\n",
    "# these columns in the analysis, the columns can be converted later\n",
    "# within the database or via python after the data is fetched\n",
    "\n",
    "event_columns_no_types_no_id = (\n",
    "    event_columns.replace(\" text\", \"\")\n",
    "    .replace(\" numeric\", \"\")\n",
    "    .replace(\" bigint\", \"\")\n",
    "    .replace(\" integer\", \"\")\n",
    "    .replace(\"id serial PRIMARY KEY,\", \"\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81ebc310-7fd9-4c6f-9a70-609ba01805dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postgres\n"
     ]
    }
   ],
   "source": [
    "with open(\"../data/gdelt_events.csv\", \"r\") as events_file, open(\n",
    "    \"../etc/postgres.password\"\n",
    ") as psql_pass_file:\n",
    "    postgres_password = psql_pass_file.read()\n",
    "    print(postgres_password)\n",
    "    conn = connect(\n",
    "        f\"host='localhost' dbname='gdelt' user='postgres' password='{postgres_password}'\"\n",
    "    )\n",
    "    cursor = conn.cursor()\n",
    "    create_events_table_cmd = f\"CREATE TABLE events({event_columns})\"\n",
    "    copy_events_cmd = f\"COPY events({event_columns_no_types_no_id}) FROM STDIN WITH (FORMAT TEXT, HEADER FALSE)\"\n",
    "    cursor.execute(create_events_table_cmd)\n",
    "    cursor.copy_expert(copy_events_cmd, events_file)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c90843-1b8b-4d5e-8599-e29d16bb0ea5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
