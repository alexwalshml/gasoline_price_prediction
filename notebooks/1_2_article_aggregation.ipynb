{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61d65efe-58c1-40da-8e36-940926480cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26894ee1-0f51-4af8-8560-bf3d134171ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pathlib\n",
    "import newspaper\n",
    "\n",
    "from psycopg2 import connect\n",
    "from urllib3.exceptions import LocationParseError\n",
    "from multiprocessing import Pool\n",
    "from math import floor, ceil\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dafffd8e-9278-4eb0-8457-747c0249c23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def article_content_fetcher(row):\n",
    "    path = pathlib.Path(\"../data/raw\")\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "    _id, url, date, day = row\n",
    "\n",
    "    text_dump = pathlib.Path(path / f\"{_id}.text\")\n",
    "    title_dump = pathlib.Path(path / f\"{_id}.title\")\n",
    "\n",
    "    if not text_dump.is_file():\n",
    "        try:\n",
    "            article = newspaper.Article(url=url)\n",
    "            article.download()\n",
    "            article.parse()\n",
    "\n",
    "            article_text = article.text\n",
    "            article_title = article.title\n",
    "\n",
    "            article_text = article_text if article_text else \"\"\n",
    "            article_title = article_title if article_title else \"\"\n",
    "\n",
    "        except (TypeError, newspaper.ArticleException, LocationParseError):\n",
    "            # TypeError will occur when there is no url\n",
    "            # ArticleException will occur when the response forbids webscraping\n",
    "            # not sure what causes LocationParseError, but it's rare\n",
    "            article_text = \"\"\n",
    "            article_title = \"\"\n",
    "\n",
    "        with text_dump.open(mode=\"w+\") as txt, title_dump.open(mode=\"w+\") as ttl:\n",
    "            txt.write(article_text)\n",
    "            ttl.write(article_title)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95bd13b0-afd9-49bb-b912-fd07e6725661",
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_writer(row, conn):\n",
    "    _id, url, date, day = row\n",
    "    path = pathlib.Path(\"../data/raw/\")\n",
    "\n",
    "    text_dump = pathlib.Path(path / f\"{_id}.text\")\n",
    "    title_dump = pathlib.Path(path / f\"{_id}.title\")\n",
    "\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    with text_dump.open(mode=\"r\") as txt, title_dump.open(mode=\"r\") as ttl:\n",
    "        title = title_dump.read_text()\n",
    "        text = text_dump.read_text()\n",
    "        cmd = f\"INSERT INTO source_text(id, source, date, day, title, text) VALUES (%s, %s, %s, %s, %s, %s)\"\n",
    "        cursor.execute(\n",
    "            cmd, (_id, url, date, day, title if title else None, text if text else None)\n",
    "        )\n",
    "\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c832b7b9-3a96-485f-b4d2-bf8141021482",
   "metadata": {},
   "outputs": [],
   "source": [
    "SQL_RANDOM_SEED = 0.42\n",
    "ENTRIES_PER_WEEK = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13041ecc-550e-447a-8c19-5a43ea02ee1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = f\"\"\"\n",
    "      DROP TABLE IF EXISTS source_text;\n",
    "      CREATE TABLE source_text(id integer PRIMARY KEY, source text, date timestamp, day text, title text, text text);\n",
    "      SELECT SETSEED ({SQL_RANDOM_SEED});\n",
    "      WITH grouped_by_week AS (\n",
    "          SELECT\n",
    "              DISTINCT ON (SOURCEURL) SOURCEURL AS source,\n",
    "              id,\n",
    "              TO_DATE(Day::text, 'YYYYMMDD') AS date,\n",
    "              Day as day,\n",
    "              RANK() OVER (PARTITION BY date_trunc('week', TO_DATE(Day::text, 'YYYYMMDD')) ORDER BY RANDOM()) as row\n",
    "          FROM events\n",
    "      )\n",
    "      SELECT\n",
    "          id,\n",
    "          source,\n",
    "          date,\n",
    "          day\n",
    "      FROM grouped_by_week\n",
    "      WHERE row <= {ENTRIES_PER_WEEK};\n",
    "      \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2272e6b-050a-496b-940a-632aa6f8e769",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84cd507-4fb9-4602-a5e6-d43f1e00788f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source article download progress 100% complete\n",
      "107942/112475 rows written to postgreSQL table\n"
     ]
    }
   ],
   "source": [
    "pool = Pool()\n",
    "with open(\"../etc/postgres.password\") as psql_pass_file:\n",
    "    postgres_password = psql_pass_file.read()\n",
    "    conn = connect(\n",
    "        f\"host='localhost' dbname='gdelt' user='postgres' password='{postgres_password}'\"\n",
    "    )\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(cmd)\n",
    "    conn.commit()\n",
    "    rows = cursor.fetchall()\n",
    "    print(\"Source article download progress 0% complete\")\n",
    "    for percent in range(100):\n",
    "        # prints progress as percents\n",
    "        bot = floor(percent * len(rows) / 100.0)\n",
    "        top = ceil((percent + 1) * len(rows) / 100.0)\n",
    "\n",
    "        pool.map(article_content_fetcher, rows[bot:top])\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        print(f\"Source article download progress {percent + 1}% complete\")\n",
    "    for n, row in enumerate(rows):\n",
    "        row_writer(row, conn)\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        print(f\"Source article download progress 100% complete\")\n",
    "        print(f\"{n + 1}/{len(rows)} rows written to postgreSQL table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb866c36-2b7b-413d-94c2-943df29bcc39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bf1c7f-0377-4259-b12c-1c109adae78f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa10c51-455b-4613-b4a8-cee00d51aa3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
